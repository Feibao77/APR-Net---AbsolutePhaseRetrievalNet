# APR-Net---AbsolutePhaseRetrievalNet
If you need more information, see our [paper]().

## Brief Introduction
APR-Net enables pixel-wise prediction of the absolute phase map from a single deformed frequency-multiplexing composite image. A nested strategy leveraging Residual U-block (RSU) and the concept of centralized information interaction (CII) are employed.

## Architecture of APR-Net
The backbone of APR-Net adopts two levels of U-shape structure (see Fig. 1). On the exterior level, the U-shape structure consists of several encoder modules and decoder modules. On the interior level, each exterior encoder or decoder is a RSU (see Fig. 2) which is also a U-shape structure. The nested U-shape structure facilitates hierarchical feature extraction, allowing the network to capture multi-scale information inherent in the input. 

![image](https://github.com/Feibao77/APR-Net---AbsolutePhaseRetrievalNet/assets/117697608/59141cb3-2b73-4161-a73c-8692bc1e3d5c)

**Fig.1.** Schematic of APR-Net.

![image](https://github.com/Feibao77/APR-Net---AbsolutePhaseRetrievalNet/assets/117697608/1ea2698c-251b-4d06-b378-f9c250ab46f2)

**Fig. 2.** Schematic of RSU. (a) RSU-L. (b) RSU-4F.

Additionally, rather than using a direct identity mapping from an exterior encoder output to the corresponding decoder input, we incorporate a relative global calibration (RGC) module (see Fig. 3) into the network to strengthen the information interaction among feature maps in diverse resolutions. 
It should be noted that there is only one learnable RGC module in APR-Net, meaning the five RGC modules displayed in Fig. 1 share the same set of filter parameters. Thus, not only En_1-En_5 achieve information interaction with En_6 via RGC, but also En_1-En_5 interact with each other due to the parameters-sharing mechanism. The detailed configurations of each encoder and decoder can be seen in our paper.

![image](https://github.com/Feibao77/APR-Net---AbsolutePhaseRetrievalNet/assets/117697608/78f780e3-3ee5-4c9d-8e70-0cad55f14ea7)

**Fig. 3.** Architecture of RGC.

## Experiments and results
### Training
#### Pre-processing
For each measurement scenario, 49 images were captured with 640 × 640 resolution. At the start, we collected 2000 groups of samples comprising miscellaneous different scenes, such as a single sphere or several isolated plaster statues. Considering that the mapping to be learned by APR-Net might be quite complicated, we performed random cropping and horizontal flipping on the captured images and the according ground truths to enhance the diversity of our dataset. Crop sizes were 480 × 480 and 320 × 320, and flip probability was set to 0.5. The augmented 4000-sized dataset was then generated by randomly selecting 2000 groups of data from the augmented dataset and incorporating them into the original 2000-sized dataset. 
#### Loss calculation
As shown in Fig. 1, we used AP_fuse as well as AP_1-AP_6 to calculate training loss, where mean square error (MSE) was deployed. This approach could allow the network to receive feedback at multiple levels of abstraction. The formula of MSE is as follows:
![image](https://github.com/Feibao77/APR-Net---AbsolutePhaseRetrievalNet/assets/117697608/8d29855f-b606-4f03-b51c-64d5d8ce2c58)



